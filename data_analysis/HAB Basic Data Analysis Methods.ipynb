{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPthHRe8RwSC+7ns4sfNMFP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2y_hY0uuMqTJ"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.stats import zscore, spearmanr, pearsonr\n","from sklearn.preprocessing import StandardScaler, PowerTransformer\n","from sklearn.linear_model import LinearRegression, Ridge\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from statsmodels.tsa.stattools import adfuller\n","from statsmodels.tsa.arima.model import ARIMA\n","from statsmodels.tsa.holtwinters import ExponentialSmoothing\n"]},{"cell_type":"code","source":["# Replace 'data.csv' with the actual path to your dataset\n","data = pd.read_csv('data.csv')\n","\n","# Display basic information about the dataset\n","print(data.info())\n","print(data.describe())\n","\n","# Quick look at the first few rows\n","data.head()\n"],"metadata":{"id":"M1XIWofnOdxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Handle missing values using time-based mean imputation\n","data.interpolate(method='time', inplace=True)\n","\n","# Detect outliers using Z-score analysis (removing points beyond 3 standard deviations)\n","z_scores = np.abs(zscore(data.select_dtypes(include=[np.number])))\n","data_cleaned = data[(z_scores < 3).all(axis=1)]\n","\n","# Check the size of the dataset after cleaning\n","print(f\"Original dataset size: {data.shape}\")\n","print(f\"Cleaned dataset size: {data_cleaned.shape}\")\n"],"metadata":{"id":"qVrCe7joOg5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize numerical columns (if needed) using StandardScaler\n","scaler = StandardScaler()\n","numerical_cols = data_cleaned.select_dtypes(include=[np.number]).columns\n","data_cleaned[numerical_cols] = scaler.fit_transform(data_cleaned[numerical_cols])\n","\n","# Apply log transformation to skewed data\n","power_transformer = PowerTransformer(method='yeo-johnson')\n","data_cleaned[numerical_cols] = power_transformer.fit_transform(data_cleaned[numerical_cols])\n"],"metadata":{"id":"HdcE2674OjG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate Pearson correlation for linear relationships\n","correlation_matrix = data_cleaned.corr(method='pearson')\n","sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n","plt.title('Correlation Matrix')\n","plt.show()\n","\n","# Example: Spearman correlation for non-linear relationships\n","temp = data_cleaned['Temperature']\n","humidity = data_cleaned['Humidity']\n","corr, _ = spearmanr(temp, humidity)\n","print(f\"Spearman correlation between Temperature and Humidity: {corr:.2f}\")\n"],"metadata":{"id":"a-3m5tGkOkyp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure the data is time-indexed\n","data_cleaned['Timestamp'] = pd.to_datetime(data_cleaned['Timestamp'])\n","data_cleaned.set_index('Timestamp', inplace=True)\n","\n","# Test stationarity (Augmented Dickey-Fuller test)\n","result = adfuller(data_cleaned['Temperature'])\n","print(f'ADF Statistic: {result[0]}')\n","print(f'p-value: {result[1]}')\n","\n","# ARIMA Model for forecasting\n","arima_model = ARIMA(data_cleaned['Temperature'], order=(1, 1, 1))\n","arima_fit = arima_model.fit()\n","print(arima_fit.summary())\n","\n","# Plot forecast\n","forecast = arima_fit.forecast(steps=30)\n","plt.plot(data_cleaned['Temperature'], label=\"Actual\")\n","plt.plot(forecast, label=\"Forecast\", color='red')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"ePsRzMFiOnno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Linear Regression\n","X = data_cleaned[['Pressure', 'Humidity']]  # Replace with predictors\n","y = data_cleaned['Temperature']  # Replace with target variable\n","reg = LinearRegression()\n","reg.fit(X, y)\n","print(f\"Linear Regression Coefficients: {reg.coef_}\")\n","\n","# Ridge Regression (to handle multicollinearity)\n","ridge = Ridge(alpha=1.0)\n","ridge.fit(X, y)\n","print(f\"Ridge Regression Coefficients: {ridge.coef_}\")\n"],"metadata":{"id":"-gYzP3H6Oovd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Principal Component Analysis (PCA)\n","pca = PCA(n_components=2)\n","pca_result = pca.fit_transform(data_cleaned[numerical_cols])\n","print(f\"Explained Variance by Components: {pca.explained_variance_ratio_}\")\n","\n","# Scatter plot of the PCA components\n","plt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', alpha=0.5)\n","plt.xlabel('Principal Component 1')\n","plt.ylabel('Principal Component 2')\n","plt.title('PCA Results')\n","plt.show()\n"],"metadata":{"id":"DJRKQm3kOqL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# K-Means Clustering (e.g., for weather types)\n","kmeans = KMeans(n_clusters=3, random_state=0)\n","clusters = kmeans.fit_predict(data_cleaned[numerical_cols])\n","data_cleaned['Cluster'] = clusters\n","\n","# Visualize clusters\n","sns.pairplot(data_cleaned, hue='Cluster', palette='Set1')\n","plt.show()\n"],"metadata":{"id":"JROXfsHnOrI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Anomaly detection using rolling Z-scores\n","rolling_mean = data_cleaned['Temperature'].rolling(window=10).mean()\n","rolling_std = data_cleaned['Temperature'].rolling(window=10).std()\n","data_cleaned['Anomaly'] = (np.abs(data_cleaned['Temperature'] - rolling_mean) > 2 * rolling_std).astype(int)\n","\n","# Plot anomalies\n","plt.plot(data_cleaned.index, data_cleaned['Temperature'], label='Temperature')\n","plt.scatter(data_cleaned.index, data_cleaned['Temperature'], c=data_cleaned['Anomaly'], cmap='coolwarm', label='Anomalies')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"tgC73rdTOsKW"},"execution_count":null,"outputs":[]}]}
